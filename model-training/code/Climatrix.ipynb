{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e0cd95",
   "metadata": {},
   "source": [
    "# IoT Weather Station Code \n",
    "\n",
    "Involves Data Preprocessing & Initial ML development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a4619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (6.5.2)\n",
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (23.0.0)\n",
      "Requirement already satisfied: fastparquet in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2025.12.0)\n",
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from plotly) (2.10.1)\n",
      "Requirement already satisfied: cramjam>=2.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fastparquet) (2025.10.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib seaborn scikit-learn plotly pyarrow fastparquet xgboost torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ddee537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import IsolationForest, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff \n",
    "import math\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db4223da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/saikeerthan/Coding/NYP/IOTA/IoT_Weather_project/model-training/code\n"
     ]
    }
   ],
   "source": [
    "#getting the directory of notebook \n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "print(f\"Current Working Directory: {cwd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a17e34e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"/Users/saikeerthan/Coding/NYP/IOTA/IoT_Weather_project/model-training/datasets/official_data.csv\")\n",
    "\n",
    "print(DATA_ROOT.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8797861",
   "metadata": {},
   "source": [
    "## Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e4b2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cidx</th>\n",
       "      <th>cattr</th>\n",
       "      <th>temp</th>\n",
       "      <th>humi</th>\n",
       "      <th>pres</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>winddirection</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>uvindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-24 20:23:02</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.746582</td>\n",
       "      <td>5.5</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-24 20:28:02</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.802490</td>\n",
       "      <td>5.3</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-24 20:33:02</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.859131</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-24 20:38:02</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>4.9</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-24 20:43:02</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>5.4</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>2026-02-02 10:26:15</td>\n",
       "      <td>1045</td>\n",
       "      <td>7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.157959</td>\n",
       "      <td>6.9</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>2026-02-02 10:31:15</td>\n",
       "      <td>1046</td>\n",
       "      <td>7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.206055</td>\n",
       "      <td>8.2</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>2026-02-02 10:36:15</td>\n",
       "      <td>1047</td>\n",
       "      <td>7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.149414</td>\n",
       "      <td>8.2</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>2026-02-02 10:41:15</td>\n",
       "      <td>1048</td>\n",
       "      <td>7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.127930</td>\n",
       "      <td>8.1</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>2026-02-02 10:46:15</td>\n",
       "      <td>1049</td>\n",
       "      <td>7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.202881</td>\n",
       "      <td>7.6</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2276 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  cidx  cattr  temp  humi         pres  windspeed  \\\n",
       "0     2026-01-24 20:23:02     1      7  28.6    74  1016.746582        5.5   \n",
       "1     2026-01-24 20:28:02     2      7  28.5    74  1016.802490        5.3   \n",
       "2     2026-01-24 20:33:02     3      7  28.6    74  1016.859131        5.0   \n",
       "3     2026-01-24 20:38:02     4      7  28.5    74  1016.934326        4.9   \n",
       "4     2026-01-24 20:43:02     5      7  28.6    74  1016.971436        5.4   \n",
       "...                   ...   ...    ...   ...   ...          ...        ...   \n",
       "2271  2026-02-02 10:26:15  1045      7  38.5    47  1018.157959        6.9   \n",
       "2272  2026-02-02 10:31:15  1046      7  38.5    47  1018.206055        8.2   \n",
       "2273  2026-02-02 10:36:15  1047      7  38.5    47  1018.149414        8.2   \n",
       "2274  2026-02-02 10:41:15  1048      7  38.5    47  1018.127930        8.1   \n",
       "2275  2026-02-02 10:46:15  1049      7  38.5    47  1018.202881        7.6   \n",
       "\n",
       "      winddirection  rainfall  uvindex  \n",
       "0                54       NaN      NaN  \n",
       "1                53       NaN      NaN  \n",
       "2                53       NaN      NaN  \n",
       "3                50       NaN      NaN  \n",
       "4                50       NaN      NaN  \n",
       "...             ...       ...      ...  \n",
       "2271             75       NaN      2.0  \n",
       "2272             73       NaN      2.0  \n",
       "2273             66       NaN      2.0  \n",
       "2274             47       NaN      2.0  \n",
       "2275             40       NaN      2.0  \n",
       "\n",
       "[2276 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieving the dataset\n",
    "\n",
    "df = pd.read_csv(DATA_ROOT) \n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d975a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates present in DF: 0\n"
     ]
    }
   ],
   "source": [
    "#checking for duplicates \n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "\n",
    "print(f\"Duplicates present in DF: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "034f83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in df: 3768\n"
     ]
    }
   ],
   "source": [
    "# checking for missing values \n",
    "\n",
    "missing = df.isnull().sum().sum()\n",
    "\n",
    "print(f\"Missing values in df: {missing}\")\n",
    "\n",
    "# missing values is because of last two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eccd8d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Dataset:\n",
      "\n",
      "1. time\n",
      "2. cidx\n",
      "3. cattr\n",
      "4. temp\n",
      "5. humi\n",
      "6. pres\n",
      "7. windspeed\n",
      "8. winddirection\n",
      "9. rainfall\n",
      "10. uvindex\n"
     ]
    }
   ],
   "source": [
    "#columns in df \n",
    "\n",
    "columns = df.columns\n",
    "\n",
    "print(\"Columns in Dataset:\\n\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd67e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cidx</th>\n",
       "      <th>cattr</th>\n",
       "      <th>temp</th>\n",
       "      <th>humi</th>\n",
       "      <th>pres</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>winddirection</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>uvindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-24 20:23:02</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.746582</td>\n",
       "      <td>5.5</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-24 20:28:02</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.802490</td>\n",
       "      <td>5.3</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-24 20:33:02</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.859131</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-24 20:38:02</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>4.9</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-24 20:43:02</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>5.4</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>2026-02-02 10:26:15</td>\n",
       "      <td>1045</td>\n",
       "      <td>7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.157959</td>\n",
       "      <td>6.9</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>2026-02-02 10:31:15</td>\n",
       "      <td>1046</td>\n",
       "      <td>7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.206055</td>\n",
       "      <td>8.2</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>2026-02-02 10:36:15</td>\n",
       "      <td>1047</td>\n",
       "      <td>7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.149414</td>\n",
       "      <td>8.2</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>2026-02-02 10:41:15</td>\n",
       "      <td>1048</td>\n",
       "      <td>7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.127930</td>\n",
       "      <td>8.1</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>2026-02-02 10:46:15</td>\n",
       "      <td>1049</td>\n",
       "      <td>7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.202881</td>\n",
       "      <td>7.6</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2197 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  cidx  cattr  temp  humi         pres  windspeed  \\\n",
       "0     2026-01-24 20:23:02     1      7  28.6    74  1016.746582        5.5   \n",
       "1     2026-01-24 20:28:02     2      7  28.5    74  1016.802490        5.3   \n",
       "2     2026-01-24 20:33:02     3      7  28.6    74  1016.859131        5.0   \n",
       "3     2026-01-24 20:38:02     4      7  28.5    74  1016.934326        4.9   \n",
       "4     2026-01-24 20:43:02     5      7  28.6    74  1016.971436        5.4   \n",
       "...                   ...   ...    ...   ...   ...          ...        ...   \n",
       "2271  2026-02-02 10:26:15  1045      7  38.5    47  1018.157959        6.9   \n",
       "2272  2026-02-02 10:31:15  1046      7  38.5    47  1018.206055        8.2   \n",
       "2273  2026-02-02 10:36:15  1047      7  38.5    47  1018.149414        8.2   \n",
       "2274  2026-02-02 10:41:15  1048      7  38.5    47  1018.127930        8.1   \n",
       "2275  2026-02-02 10:46:15  1049      7  38.5    47  1018.202881        7.6   \n",
       "\n",
       "      winddirection  rainfall  uvindex  \n",
       "0                54       NaN      NaN  \n",
       "1                53       NaN      NaN  \n",
       "2                53       NaN      NaN  \n",
       "3                50       NaN      NaN  \n",
       "4                50       NaN      NaN  \n",
       "...             ...       ...      ...  \n",
       "2271             75       NaN      2.0  \n",
       "2272             73       NaN      2.0  \n",
       "2273             66       NaN      2.0  \n",
       "2274             47       NaN      2.0  \n",
       "2275             40       NaN      2.0  \n",
       "\n",
       "[2197 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop entries where cattr is below 7\n",
    "\n",
    "df = df[df[\"cattr\"] >=7]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f28bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Columns:Index(['time', 'temp', 'humi', 'pres'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns_to_delete = [\"cattr\", \"windspeed\", \"winddirection\", \"rainfall\", \"uvindex\", \"cidx\"]\n",
    "\n",
    "df = df.drop(columns=columns_to_delete)\n",
    "\n",
    "columns = df.columns\n",
    "print(f\"Remaining Columns:{columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bb6b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time     object\n",
      "temp    float64\n",
      "humi      int64\n",
      "pres    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check the dtype of every column in the df \n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fede5051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Dtypes for columns in df: time    datetime64[ns]\n",
      "temp           float64\n",
      "humi             int64\n",
      "pres           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "\n",
    "print(f\"New Dtypes for columns in df: {df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fdfa78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to datetime safely\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "\n",
    "# Drop invalid timestamps\n",
    "df = df.dropna(subset=[\"time\"])\n",
    "\n",
    "# Sort chronologically (CRITICAL for time-series ML)\n",
    "df = df.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "# (Recommended) Set as index if doing time-based operations later\n",
    "df = df.set_index(\"time\")\n",
    "\n",
    "# Extract time features (daily patterns help weather prediction)\n",
    "df[\"hour\"] = df.index.hour\n",
    "df[\"dayofweek\"] = df.index.dayofweek\n",
    "\n",
    "# Cyclic encoding (prevents 23 → 0 discontinuity)\n",
    "df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "796f2b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>humi</th>\n",
       "      <th>pres</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2026-01-24 20:23:02</th>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.746582</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 20:28:02</th>\n",
       "      <td>28.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.802490</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 20:33:02</th>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.859131</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 20:38:02</th>\n",
       "      <td>28.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 20:43:02</th>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-02 10:26:15</th>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.157959</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-02 10:31:15</th>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.206055</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-02 10:36:15</th>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.149414</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-02 10:41:15</th>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.127930</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-02 10:46:15</th>\n",
       "      <td>38.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1018.202881</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2197 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temp  humi         pres  hour  dayofweek  hour_sin  \\\n",
       "time                                                                      \n",
       "2026-01-24 20:23:02  28.6    74  1016.746582    20          5 -0.866025   \n",
       "2026-01-24 20:28:02  28.5    74  1016.802490    20          5 -0.866025   \n",
       "2026-01-24 20:33:02  28.6    74  1016.859131    20          5 -0.866025   \n",
       "2026-01-24 20:38:02  28.5    74  1016.934326    20          5 -0.866025   \n",
       "2026-01-24 20:43:02  28.6    74  1016.971436    20          5 -0.866025   \n",
       "...                   ...   ...          ...   ...        ...       ...   \n",
       "2026-02-02 10:26:15  38.5    47  1018.157959    10          0  0.500000   \n",
       "2026-02-02 10:31:15  38.5    47  1018.206055    10          0  0.500000   \n",
       "2026-02-02 10:36:15  38.5    47  1018.149414    10          0  0.500000   \n",
       "2026-02-02 10:41:15  38.5    47  1018.127930    10          0  0.500000   \n",
       "2026-02-02 10:46:15  38.5    47  1018.202881    10          0  0.500000   \n",
       "\n",
       "                     hour_cos  \n",
       "time                           \n",
       "2026-01-24 20:23:02  0.500000  \n",
       "2026-01-24 20:28:02  0.500000  \n",
       "2026-01-24 20:33:02  0.500000  \n",
       "2026-01-24 20:38:02  0.500000  \n",
       "2026-01-24 20:43:02  0.500000  \n",
       "...                       ...  \n",
       "2026-02-02 10:26:15 -0.866025  \n",
       "2026-02-02 10:31:15 -0.866025  \n",
       "2026-02-02 10:36:15 -0.866025  \n",
       "2026-02-02 10:41:15 -0.866025  \n",
       "2026-02-02 10:46:15 -0.866025  \n",
       "\n",
       "[2197 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "176f7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new df \n",
    "\n",
    "df.to_csv(\"df_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba0c7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57ef0d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (23.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "ERROR: unknown command \"instlal\" - maybe you meant \"install\"\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U pyarrow\n",
    "%pip instlal -U fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e236336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ML-ready dataset created\n",
      "(2182, 19)\n"
     ]
    }
   ],
   "source": [
    "WEATHER_COLS = [\"temp\", \"humi\", \"pres\"]\n",
    "\n",
    "for col in WEATHER_COLS:\n",
    "    df[f\"{col}_lag1\"] = df[col].shift(1)\n",
    "    df[f\"{col}_lag2\"] = df[col].shift(2)\n",
    "    df[f\"{col}_lag3\"] = df[col].shift(3)\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ CREATE NEXT-HOUR TARGETS\n",
    "# -----------------------------\n",
    "# ⚠ Adjust this based on sampling rate\n",
    "# If data every 5 min → 12 steps = 1 hour\n",
    "# If data every 10 min → 6 steps\n",
    "# If data hourly → 1 step\n",
    "\n",
    "SHIFT_STEPS = 12   # ← CHANGE IF NEEDED\n",
    "\n",
    "for col in WEATHER_COLS:\n",
    "    df[f\"{col}_next1h\"] = df[col].shift(-SHIFT_STEPS)\n",
    "\n",
    "# -----------------------------\n",
    "# 6️⃣ REMOVE NAN ROWS FROM SHIFTS\n",
    "# -----------------------------\n",
    "df = df.dropna()\n",
    "\n",
    "# -----------------------------\n",
    "# 7️⃣ OPTIONAL: DROP RAW HOUR IF USING SIN/COS\n",
    "# -----------------------------\n",
    "# df = df.drop(columns=[\"hour\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 8️⃣ SAVE ML-READY DATASET\n",
    "# -----------------------------\n",
    "df.to_parquet(\"weather_ml_ready.parquet\")\n",
    "df.to_csv(\"weather_ml_ready.csv\")\n",
    "\n",
    "print(\"✅ ML-ready dataset created\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f90ab",
   "metadata": {},
   "source": [
    "## Model Training Code \n",
    "\n",
    "Model Name - Climatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279671e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import pathlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a94947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/saikeerthan/Coding/NYP/IOTA/IoT_Weather_project/model-training/code\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current Working Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0a81b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Root Exists!\n"
     ]
    }
   ],
   "source": [
    "ML_DATA_ROOT = Path(\"/Users/saikeerthan/Coding/NYP/IOTA/IoT_Weather_project/model-training/datasets/weather_ml_ready.csv\")\n",
    "\n",
    "if ML_DATA_ROOT.exists():\n",
    "    print(\"Data Root Exists!\")\n",
    "else: \n",
    "    print(\"Data Root doesn't exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58bd7167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temp</th>\n",
       "      <th>humi</th>\n",
       "      <th>pres</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>temp_lag1</th>\n",
       "      <th>temp_lag2</th>\n",
       "      <th>temp_lag3</th>\n",
       "      <th>humi_lag1</th>\n",
       "      <th>humi_lag2</th>\n",
       "      <th>humi_lag3</th>\n",
       "      <th>pres_lag1</th>\n",
       "      <th>pres_lag2</th>\n",
       "      <th>pres_lag3</th>\n",
       "      <th>temp_next1h</th>\n",
       "      <th>humi_next1h</th>\n",
       "      <th>pres_next1h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-24 20:38:02</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1016.859131</td>\n",
       "      <td>1016.802490</td>\n",
       "      <td>1016.746582</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1017.522461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-24 20:43:02</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>1016.859131</td>\n",
       "      <td>1016.802490</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1017.663086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-24 20:48:02</td>\n",
       "      <td>28.9</td>\n",
       "      <td>74</td>\n",
       "      <td>1017.078125</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>1016.859131</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1017.696777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-24 20:53:02</td>\n",
       "      <td>28.7</td>\n",
       "      <td>74</td>\n",
       "      <td>1017.150879</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1017.078125</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1017.770752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-24 20:58:02</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1017.206299</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.7</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1017.150879</td>\n",
       "      <td>1017.078125</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1017.850830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>2026-02-02 09:26:15</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48</td>\n",
       "      <td>1017.980957</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.2</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1018.028076</td>\n",
       "      <td>1017.984131</td>\n",
       "      <td>1017.997070</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.157959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>2026-02-02 09:31:15</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48</td>\n",
       "      <td>1018.037842</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1017.980957</td>\n",
       "      <td>1018.028076</td>\n",
       "      <td>1017.984131</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.206055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>2026-02-02 09:36:15</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48</td>\n",
       "      <td>1018.024414</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1018.037842</td>\n",
       "      <td>1017.980957</td>\n",
       "      <td>1018.028076</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.149414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>2026-02-02 09:41:15</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48</td>\n",
       "      <td>1018.083984</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1018.024414</td>\n",
       "      <td>1018.037842</td>\n",
       "      <td>1017.980957</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.127930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>2026-02-02 09:46:15</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48</td>\n",
       "      <td>1018.033691</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1018.083984</td>\n",
       "      <td>1018.024414</td>\n",
       "      <td>1018.037842</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.202881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  temp  humi         pres  hour  dayofweek  hour_sin  \\\n",
       "0     2026-01-24 20:38:02  28.5    74  1016.934326    20          5 -0.866025   \n",
       "1     2026-01-24 20:43:02  28.6    74  1016.971436    20          5 -0.866025   \n",
       "2     2026-01-24 20:48:02  28.9    74  1017.078125    20          5 -0.866025   \n",
       "3     2026-01-24 20:53:02  28.7    74  1017.150879    20          5 -0.866025   \n",
       "4     2026-01-24 20:58:02  28.5    74  1017.206299    20          5 -0.866025   \n",
       "...                   ...   ...   ...          ...   ...        ...       ...   \n",
       "2177  2026-02-02 09:26:15  38.3    48  1017.980957     9          0  0.707107   \n",
       "2178  2026-02-02 09:31:15  38.3    48  1018.037842     9          0  0.707107   \n",
       "2179  2026-02-02 09:36:15  38.3    48  1018.024414     9          0  0.707107   \n",
       "2180  2026-02-02 09:41:15  38.3    48  1018.083984     9          0  0.707107   \n",
       "2181  2026-02-02 09:46:15  38.3    48  1018.033691     9          0  0.707107   \n",
       "\n",
       "      hour_cos  temp_lag1  temp_lag2  temp_lag3  humi_lag1  humi_lag2  \\\n",
       "0     0.500000       28.6       28.5       28.6       74.0       74.0   \n",
       "1     0.500000       28.5       28.6       28.5       74.0       74.0   \n",
       "2     0.500000       28.6       28.5       28.6       74.0       74.0   \n",
       "3     0.500000       28.9       28.6       28.5       74.0       74.0   \n",
       "4     0.500000       28.7       28.9       28.6       74.0       74.0   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "2177 -0.707107       38.1       38.3       38.2       49.0       49.0   \n",
       "2178 -0.707107       38.3       38.1       38.3       48.0       49.0   \n",
       "2179 -0.707107       38.3       38.3       38.1       48.0       48.0   \n",
       "2180 -0.707107       38.3       38.3       38.3       48.0       48.0   \n",
       "2181 -0.707107       38.3       38.3       38.3       48.0       48.0   \n",
       "\n",
       "      humi_lag3    pres_lag1    pres_lag2    pres_lag3  temp_next1h  \\\n",
       "0          74.0  1016.859131  1016.802490  1016.746582         28.5   \n",
       "1          74.0  1016.934326  1016.859131  1016.802490         28.5   \n",
       "2          74.0  1016.971436  1016.934326  1016.859131         28.5   \n",
       "3          74.0  1017.078125  1016.971436  1016.934326         28.5   \n",
       "4          74.0  1017.150879  1017.078125  1016.971436         28.5   \n",
       "...         ...          ...          ...          ...          ...   \n",
       "2177       49.0  1018.028076  1017.984131  1017.997070         38.5   \n",
       "2178       49.0  1017.980957  1018.028076  1017.984131         38.5   \n",
       "2179       49.0  1018.037842  1017.980957  1018.028076         38.5   \n",
       "2180       48.0  1018.024414  1018.037842  1017.980957         38.5   \n",
       "2181       48.0  1018.083984  1018.024414  1018.037842         38.5   \n",
       "\n",
       "      humi_next1h  pres_next1h  \n",
       "0            75.0  1017.522461  \n",
       "1            75.0  1017.663086  \n",
       "2            75.0  1017.696777  \n",
       "3            75.0  1017.770752  \n",
       "4            75.0  1017.850830  \n",
       "...           ...          ...  \n",
       "2177         47.0  1018.157959  \n",
       "2178         47.0  1018.206055  \n",
       "2179         47.0  1018.149414  \n",
       "2180         47.0  1018.127930  \n",
       "2181         47.0  1018.202881  \n",
       "\n",
       "[2182 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(ML_DATA_ROOT)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8945fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets \n",
    "TARGETS = [\"temp_next1h\", \"humi_next1h\", \"pres_next1h\"]\n",
    "\n",
    "# Drop rows with missing target(s)\n",
    "df = df.dropna(subset=TARGETS).reset_index(drop=True)\n",
    "\n",
    "exclude_cols = set(TARGETS)\n",
    "\n",
    "# If your dataset has time columns you don't want as raw strings, exclude them:\n",
    "for maybe_time_col in [\"time\", \"timestamp\", \"datetime\", \"date\"]:\n",
    "    if maybe_time_col in df.columns:\n",
    "        exclude_cols.add(maybe_time_col)\n",
    "\n",
    "# Keep numeric features only\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [c for c in numeric_cols if c not in exclude_cols]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[TARGETS].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e14c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 2182\n",
      "Train: 1527  Val: 327  Test: 328\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3) Train / Val / Test split (time-based)\n",
    "# =========================\n",
    "n = len(df)\n",
    "train_end = int(n * 0.70)\n",
    "val_end   = int(n * 0.85)  # train 70%, val 15%, test 15%\n",
    "\n",
    "X_train, y_train = X.iloc[:train_end], y.iloc[:train_end]\n",
    "X_val,   y_val   = X.iloc[train_end:val_end], y.iloc[train_end:val_end]\n",
    "X_test,  y_test  = X.iloc[val_end:], y.iloc[val_end:]\n",
    "\n",
    "print(f\"Total rows: {n}\")\n",
    "print(f\"Train: {len(X_train)}  Val: {len(X_val)}  Test: {len(X_test)}\")\n",
    "\n",
    "# TimeSeries CV inside TRAIN only\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def report_split(y_true, y_pred, split_name=\"SPLIT\", model_name=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred, multioutput=\"raw_values\")\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred, multioutput=\"raw_values\"))\n",
    "    r2 = r2_score(y_true, y_pred, multioutput=\"raw_values\")\n",
    "\n",
    "    print(f\"\\n===== {model_name} on {split_name} =====\")\n",
    "    for i, t in enumerate(TARGETS):\n",
    "        print(f\"{t}:  MAE={mae[i]:.4f}  RMSE={rmse[i]:.4f}  R2={r2[i]:.4f}\")\n",
    "    print(f\"Avg MAE: {float(np.mean(mae)):.4f}\")\n",
    "\n",
    "def avg_mae(y_true, y_pred) -> float:\n",
    "    mae = mean_absolute_error(y_true, y_pred, multioutput=\"raw_values\")\n",
    "    return float(np.mean(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef15963",
   "metadata": {},
   "source": [
    "### Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f778821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Ridge alpha: 215.44346900318823\n",
      "\n",
      "===== Ridge on VAL =====\n",
      "temp_next1h:  MAE=0.5847  RMSE=0.6671  R2=0.3522\n",
      "humi_next1h:  MAE=0.8879  RMSE=1.0851  R2=0.8246\n",
      "pres_next1h:  MAE=0.5267  RMSE=0.6301  R2=0.7695\n",
      "Avg MAE: 0.6664\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 4) Ridge: Pipeline + GridSearch (TRAIN only)\n",
    "# =========================\n",
    "ridge_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", MultiOutputRegressor(\n",
    "        Ridge(random_state=42, max_iter=20000)\n",
    "    ))\n",
    "])\n",
    "\n",
    "ridge_param_grid = {\n",
    "    \"model__estimator__alpha\": np.logspace(-4, 4, 25)  # robust sweep\n",
    "}\n",
    "\n",
    "ridge_search = GridSearchCV(\n",
    "    estimator=ridge_pipe,\n",
    "    param_grid=ridge_param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=tscv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ridge_search.fit(X_train, y_train)\n",
    "best_ridge = ridge_search.best_estimator_\n",
    "best_ridge_alpha = ridge_search.best_params_[\"model__estimator__alpha\"]\n",
    "print(\"\\nBest Ridge alpha:\", best_ridge_alpha)\n",
    "\n",
    "# Evaluate Ridge on VAL\n",
    "ridge_val_pred = best_ridge.predict(X_val)\n",
    "report_split(y_val.values, ridge_val_pred, split_name=\"VAL\", model_name=\"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b420e",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6feec359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best ElasticNet params: {'model__estimator__alpha': np.float64(0.06660846290809161), 'model__estimator__l1_ratio': 0.9}\n",
      "\n",
      "===== ElasticNet on VAL =====\n",
      "temp_next1h:  MAE=0.4811  RMSE=0.5455  R2=0.5668\n",
      "humi_next1h:  MAE=0.9008  RMSE=1.1164  R2=0.8144\n",
      "pres_next1h:  MAE=0.5307  RMSE=0.6365  R2=0.7648\n",
      "Avg MAE: 0.6375\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5) ElasticNet: Pipeline + GridSearch (TRAIN only)\n",
    "# =========================\n",
    "enet_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", MultiOutputRegressor(\n",
    "        ElasticNet(\n",
    "            random_state=42,\n",
    "            max_iter=50000,\n",
    "            tol=1e-4,\n",
    "            selection=\"cyclic\"\n",
    "        )\n",
    "    ))\n",
    "])\n",
    "\n",
    "enet_param_grid = {\n",
    "    \"model__estimator__alpha\": np.logspace(-4, 2, 18),     # 1e-4 ... 1e2\n",
    "    \"model__estimator__l1_ratio\": [0.05, 0.1, 0.2, 0.35, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "enet_search = GridSearchCV(\n",
    "    estimator=enet_pipe,\n",
    "    param_grid=enet_param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=tscv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "enet_search.fit(X_train, y_train)\n",
    "best_enet = enet_search.best_estimator_\n",
    "print(\"\\nBest ElasticNet params:\", enet_search.best_params_)\n",
    "\n",
    "# Evaluate ElasticNet on VAL\n",
    "enet_val_pred = best_enet.predict(X_val)\n",
    "report_split(y_val.values, enet_val_pred, split_name=\"VAL\", model_name=\"ElasticNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4c1d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected model (by VAL avg MAE): ELASTICNET\n",
      "Ridge VAL avg MAE: 0.6664\n",
      "Enet  VAL avg MAE: 0.6375\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 6) Select model using VAL performance\n",
    "# =========================\n",
    "ridge_val_mae = avg_mae(y_val.values, ridge_val_pred)\n",
    "enet_val_mae  = avg_mae(y_val.values, enet_val_pred)\n",
    "\n",
    "if ridge_val_mae <= enet_val_mae:\n",
    "    selected_name = \"ridge\"\n",
    "    selected_model = best_ridge\n",
    "else:\n",
    "    selected_name = \"elasticnet\"\n",
    "    selected_model = best_enet\n",
    "\n",
    "print(f\"\\nSelected model (by VAL avg MAE): {selected_name.upper()}\")\n",
    "print(f\"Ridge VAL avg MAE: {ridge_val_mae:.4f}\")\n",
    "print(f\"Enet  VAL avg MAE: {enet_val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1affbcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ELASTICNET on TEST =====\n",
      "temp_next1h:  MAE=0.2849  RMSE=0.3679  R2=0.7898\n",
      "humi_next1h:  MAE=0.7788  RMSE=0.9512  R2=0.7631\n",
      "pres_next1h:  MAE=0.4991  RMSE=0.5864  R2=0.7630\n",
      "Avg MAE: 0.5209\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 7) Refit selected model on TRAIN+VAL (best practice), then test\n",
    "# =========================\n",
    "X_trainval = pd.concat([X_train, X_val], axis=0)\n",
    "y_trainval = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "selected_model.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Evaluate on TEST\n",
    "test_pred = selected_model.predict(X_test)\n",
    "report_split(y_test.values, test_pred, split_name=\"TEST\", model_name=selected_name.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb37787a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== PERSISTENCE BASELINE on TEST =====\n",
      "temp_next1h:  MAE=0.2555  RMSE=0.3406  R2=0.8198\n",
      "humi_next1h:  MAE=0.6768  RMSE=0.9969  R2=0.7398\n",
      "pres_next1h:  MAE=0.5426  RMSE=0.6325  R2=0.7243\n",
      "Avg MAE: 0.4916\n"
     ]
    }
   ],
   "source": [
    "# ----- Baseline: persistence (next hour = current value) -----\n",
    "# Assuming your features include current readings named temp, humi, pres\n",
    "# If not, use the closest available like temp_lag1 as \"current\".\n",
    "def persistence_baseline(df_features, y_true, use=\"current\"):\n",
    "    # prefer current if present; else fall back to lag1\n",
    "    temp_col = \"temp\" if \"temp\" in df_features.columns else \"temp_lag1\"\n",
    "    humi_col = \"humi\" if \"humi\" in df_features.columns else \"humi_lag1\"\n",
    "    pres_col = \"pres\" if \"pres\" in df_features.columns else \"pres_lag1\"\n",
    "\n",
    "    y_pred = np.column_stack([\n",
    "        df_features[temp_col].values,\n",
    "        df_features[humi_col].values,\n",
    "        df_features[pres_col].values\n",
    "    ])\n",
    "    return y_pred\n",
    "\n",
    "baseline_test_pred = persistence_baseline(X_test, y_test.values)\n",
    "report_split(y_test.values, baseline_test_pred, split_name=\"TEST\", model_name=\"PERSISTENCE BASELINE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0631d508",
   "metadata": {},
   "source": [
    "### Tree-Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89a1a6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-3.2.0-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from xgboost) (2.2.6)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from xgboost) (1.15.3)\n",
      "Using cached xgboost-3.2.0-py3-none-macosx_12_0_arm64.whl (2.3 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "014d12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5102621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Load dataset\n",
    "# =========================\n",
    "CSV_PATH = \"/Users/saikeerthan/Coding/NYP/IOTA/IoT_Weather_project/model-training/datasets/weather_ml_ready.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "TARGETS = [\"temp_next1h\", \"humi_next1h\", \"pres_next1h\"]\n",
    "df = df.dropna(subset=TARGETS).reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# 2) Features = numeric cols except targets (and exclude raw time cols if present)\n",
    "# =========================\n",
    "exclude_cols = set(TARGETS)\n",
    "for maybe_time_col in [\"time\", \"timestamp\", \"datetime\", \"date\"]:\n",
    "    if maybe_time_col in df.columns:\n",
    "        exclude_cols.add(maybe_time_col)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [c for c in numeric_cols if c not in exclude_cols]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[TARGETS].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "676981cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: total=2182 train=1527 val=327 test=328\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3) Train / Val / Test split (time-based)\n",
    "# =========================\n",
    "n = len(df)\n",
    "train_end = int(n * 0.70)\n",
    "val_end   = int(n * 0.85)\n",
    "\n",
    "X_train, y_train = X.iloc[:train_end], y.iloc[:train_end]\n",
    "X_val,   y_val   = X.iloc[train_end:val_end], y.iloc[train_end:val_end]\n",
    "X_test,  y_test  = X.iloc[val_end:], y.iloc[val_end:]\n",
    "\n",
    "print(f\"Rows: total={n} train={len(X_train)} val={len(X_val)} test={len(X_test)}\")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "\n",
    "def report_split(y_true, y_pred, split_name=\"SPLIT\", model_name=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred, multioutput=\"raw_values\")\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred, multioutput=\"raw_values\"))\n",
    "    r2 = r2_score(y_true, y_pred, multioutput=\"raw_values\")\n",
    "\n",
    "    print(f\"\\n===== {model_name} on {split_name} =====\")\n",
    "    for i, t in enumerate(TARGETS):\n",
    "        print(f\"{t}:  MAE={mae[i]:.4f}  RMSE={rmse[i]:.4f}  R2={r2[i]:.4f}\")\n",
    "    print(f\"Avg MAE: {float(np.mean(mae)):.4f}\")\n",
    "\n",
    "\n",
    "def avg_mae(y_true, y_pred) -> float:\n",
    "    return float(np.mean(mean_absolute_error(y_true, y_pred, multioutput=\"raw_values\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "663e03b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== PERSISTENCE BASELINE on TEST =====\n",
      "temp_next1h:  MAE=0.2555  RMSE=0.3406  R2=0.8198\n",
      "humi_next1h:  MAE=0.6768  RMSE=0.9969  R2=0.7398\n",
      "pres_next1h:  MAE=0.5426  RMSE=0.6325  R2=0.7243\n",
      "Avg MAE: 0.4916\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 4) Persistence baseline (strong baseline)\n",
    "# =========================\n",
    "def persistence_baseline(df_features: pd.DataFrame):\n",
    "    # prefer current columns if present; else lag1 as proxy\n",
    "    temp_col = \"temp\" if \"temp\" in df_features.columns else \"temp_lag1\"\n",
    "    humi_col = \"humi\" if \"humi\" in df_features.columns else \"humi_lag1\"\n",
    "    pres_col = \"pres\" if \"pres\" in df_features.columns else \"pres_lag1\"\n",
    "\n",
    "    return np.column_stack([\n",
    "        df_features[temp_col].values,\n",
    "        df_features[humi_col].values,\n",
    "        df_features[pres_col].values\n",
    "    ])\n",
    "\n",
    "base_test_pred = persistence_baseline(X_test)\n",
    "report_split(y_test.values, base_test_pred, split_name=\"TEST\", model_name=\"PERSISTENCE BASELINE\")\n",
    "baseline_test_mae = avg_mae(y_test.values, base_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "003c57e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) Models + robust grids (not crazy big)\n",
    "# =========================\n",
    "candidates = []\n",
    "\n",
    "# A) HistGradientBoosting (fast + strong)\n",
    "hgb = MultiOutputRegressor(\n",
    "    HistGradientBoostingRegressor(random_state=42)\n",
    ")\n",
    "hgb_grid = {\n",
    "    \"estimator__learning_rate\": [0.03, 0.06, 0.1],\n",
    "    \"estimator__max_depth\": [3, 5, None],\n",
    "    \"estimator__max_leaf_nodes\": [31, 63, 127],\n",
    "    \"estimator__min_samples_leaf\": [10, 20, 40],\n",
    "    \"estimator__l2_regularization\": [0.0, 0.1, 1.0],\n",
    "}\n",
    "candidates.append((\"HGB\", hgb, hgb_grid))\n",
    "\n",
    "# B) ExtraTrees (often excellent on tabular)\n",
    "etr = MultiOutputRegressor(\n",
    "    ExtraTreesRegressor(random_state=42, n_jobs=-1)\n",
    ")\n",
    "etr_grid = {\n",
    "    \"estimator__n_estimators\": [300, 600],\n",
    "    \"estimator__max_depth\": [None, 10, 20],\n",
    "    \"estimator__min_samples_leaf\": [1, 2, 5],\n",
    "    \"estimator__max_features\": [\"sqrt\", 0.7, 1.0],\n",
    "}\n",
    "candidates.append((\"EXTRATREES\", etr, etr_grid))\n",
    "\n",
    "# C) RandomForest (solid baseline)\n",
    "rf = MultiOutputRegressor(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    ")\n",
    "rf_grid = {\n",
    "    \"estimator__n_estimators\": [300, 600],\n",
    "    \"estimator__max_depth\": [None, 10, 20],\n",
    "    \"estimator__min_samples_leaf\": [1, 2, 5],\n",
    "    \"estimator__max_features\": [\"sqrt\", 0.7, 1.0],\n",
    "}\n",
    "candidates.append((\"RANDOMFOREST\", rf, rf_grid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2c31209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning HGB (TRAIN only) ---\n",
      "Best params: {'estimator__l2_regularization': 0.1, 'estimator__learning_rate': 0.03, 'estimator__max_depth': 5, 'estimator__max_leaf_nodes': 31, 'estimator__min_samples_leaf': 40}\n",
      "\n",
      "===== HGB on VAL =====\n",
      "temp_next1h:  MAE=0.5112  RMSE=0.6213  R2=0.4382\n",
      "humi_next1h:  MAE=0.7049  RMSE=0.9611  R2=0.8624\n",
      "pres_next1h:  MAE=0.3150  RMSE=0.3914  R2=0.9110\n",
      "Avg MAE: 0.5103\n",
      "\n",
      "--- Tuning EXTRATREES (TRAIN only) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'estimator__max_depth': None, 'estimator__max_features': 0.7, 'estimator__min_samples_leaf': 5, 'estimator__n_estimators': 600}\n",
      "\n",
      "===== EXTRATREES on VAL =====\n",
      "temp_next1h:  MAE=0.3585  RMSE=0.4846  R2=0.6582\n",
      "humi_next1h:  MAE=0.6618  RMSE=0.9080  R2=0.8772\n",
      "pres_next1h:  MAE=0.2670  RMSE=0.3345  R2=0.9350\n",
      "Avg MAE: 0.4291\n",
      "\n",
      "--- Tuning RANDOMFOREST (TRAIN only) ---\n",
      "Best params: {'estimator__max_depth': 20, 'estimator__max_features': 'sqrt', 'estimator__min_samples_leaf': 2, 'estimator__n_estimators': 300}\n",
      "\n",
      "===== RANDOMFOREST on VAL =====\n",
      "temp_next1h:  MAE=0.3597  RMSE=0.4933  R2=0.6457\n",
      "humi_next1h:  MAE=0.7934  RMSE=1.0704  R2=0.8294\n",
      "pres_next1h:  MAE=0.2677  RMSE=0.3281  R2=0.9375\n",
      "Avg MAE: 0.4736\n",
      "\n",
      "Selected by VAL avg MAE: EXTRATREES (VAL avg MAE=0.4291)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 6) Tune each model on TRAIN (TimeSeriesSplit), choose by VAL\n",
    "# =========================\n",
    "best_name = None\n",
    "best_model = None\n",
    "best_val_mae = float(\"inf\")\n",
    "\n",
    "for name, model, grid in candidates:\n",
    "    print(f\"\\n--- Tuning {name} (TRAIN only) ---\")\n",
    "\n",
    "    search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=grid,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    tuned = search.best_estimator_\n",
    "    print(\"Best params:\", search.best_params_)\n",
    "\n",
    "    val_pred = tuned.predict(X_val)\n",
    "    report_split(y_val.values, val_pred, split_name=\"VAL\", model_name=name)\n",
    "    val_mae = avg_mae(y_val.values, val_pred)\n",
    "\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_name = name\n",
    "        best_model = tuned\n",
    "\n",
    "print(f\"\\nSelected by VAL avg MAE: {best_name} (VAL avg MAE={best_val_mae:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fe90d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== EXTRATREES on TEST =====\n",
      "temp_next1h:  MAE=0.2385  RMSE=0.3105  R2=0.8503\n",
      "humi_next1h:  MAE=0.7612  RMSE=0.9387  R2=0.7693\n",
      "pres_next1h:  MAE=0.3088  RMSE=0.3938  R2=0.8931\n",
      "Avg MAE: 0.4361\n",
      "\n",
      "Baseline TEST avg MAE: 0.4916\n",
      "EXTRATREES TEST avg MAE: 0.4361\n",
      "✅ Tree model beats persistence baseline overall on TEST.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 7) Refit selected on TRAIN+VAL, evaluate on TEST\n",
    "# =========================\n",
    "X_trainval = pd.concat([X_train, X_val], axis=0)\n",
    "y_trainval = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "best_model.fit(X_trainval, y_trainval)\n",
    "\n",
    "test_pred = best_model.predict(X_test)\n",
    "report_split(y_test.values, test_pred, split_name=\"TEST\", model_name=best_name)\n",
    "tree_test_mae = avg_mae(y_test.values, test_pred)\n",
    "\n",
    "print(f\"\\nBaseline TEST avg MAE: {baseline_test_mae:.4f}\")\n",
    "print(f\"{best_name} TEST avg MAE: {tree_test_mae:.4f}\")\n",
    "\n",
    "if tree_test_mae < baseline_test_mae:\n",
    "    print(\"✅ Tree model beats persistence baseline overall on TEST.\")\n",
    "else:\n",
    "    print(\"⚠️ Tree model does NOT beat persistence baseline overall on TEST (still may beat it for one target).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed99b07",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9209339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning XGB (TRAIN only) ---\n",
      "Best XGB params: {'estimator__colsample_bytree': 0.7, 'estimator__learning_rate': 0.08, 'estimator__max_depth': 3, 'estimator__min_child_weight': 1, 'estimator__n_estimators': 300, 'estimator__reg_lambda': 10.0, 'estimator__subsample': 0.7}\n",
      "\n",
      "===== XGB on VAL =====\n",
      "temp_next1h:  MAE=0.4069  RMSE=0.5845  R2=0.5027\n",
      "humi_next1h:  MAE=0.7682  RMSE=1.0914  R2=0.8226\n",
      "pres_next1h:  MAE=0.3107  RMSE=0.3819  R2=0.9153\n",
      "Avg MAE: 0.4953\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5) XGBoost model + tuning (TRAIN only)\n",
    "# =========================\n",
    "# Good defaults for tabular regression; fast + robust.\n",
    "xgb_base = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",          # fast on CPU\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"mae\",\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb = MultiOutputRegressor(xgb_base)\n",
    "\n",
    "# A compact but strong grid (won't take forever)\n",
    "param_grid = {\n",
    "    \"estimator__n_estimators\": [300, 600, 900],\n",
    "    \"estimator__learning_rate\": [0.03, 0.05, 0.08],\n",
    "    \"estimator__max_depth\": [3, 4, 6],\n",
    "    \"estimator__subsample\": [0.7, 0.9, 1.0],\n",
    "    \"estimator__colsample_bytree\": [0.7, 0.9, 1.0],\n",
    "    \"estimator__min_child_weight\": [1, 5, 10],\n",
    "    \"estimator__reg_lambda\": [1.0, 5.0, 10.0],   # L2\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"\\n--- Tuning XGB (TRAIN only) ---\")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = search.best_estimator_\n",
    "print(\"Best XGB params:\", search.best_params_)\n",
    "\n",
    "# VAL\n",
    "val_pred = best_xgb.predict(X_val)\n",
    "report_split(y_val.values, val_pred, split_name=\"VAL\", model_name=\"XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa20c6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== XGB on TEST =====\n",
      "temp_next1h:  MAE=0.2347  RMSE=0.3632  R2=0.7952\n",
      "humi_next1h:  MAE=0.7568  RMSE=0.9473  R2=0.7651\n",
      "pres_next1h:  MAE=0.2801  RMSE=0.3400  R2=0.9204\n",
      "Avg MAE: 0.4239\n",
      "\n",
      "Baseline TEST avg MAE: 0.4916\n",
      "XGB TEST avg MAE: 0.4239\n",
      "✅ XGB beats persistence baseline overall on TEST.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 6) Refit on TRAIN+VAL, evaluate on TEST\n",
    "# =========================\n",
    "X_trainval = pd.concat([X_train, X_val], axis=0)\n",
    "y_trainval = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "best_xgb.fit(X_trainval, y_trainval)\n",
    "\n",
    "test_pred = best_xgb.predict(X_test)\n",
    "report_split(y_test.values, test_pred, split_name=\"TEST\", model_name=\"XGB\")\n",
    "xgb_test_mae = avg_mae(y_test.values, test_pred)\n",
    "\n",
    "print(f\"\\nBaseline TEST avg MAE: {baseline_test_mae:.4f}\")\n",
    "print(f\"XGB TEST avg MAE: {xgb_test_mae:.4f}\")\n",
    "\n",
    "if xgb_test_mae < baseline_test_mae:\n",
    "    print(\"✅ XGB beats persistence baseline overall on TEST.\")\n",
    "else:\n",
    "    print(\"⚠️ XGB does NOT beat persistence baseline overall on TEST.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d02e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Good direction to discuss first.\n",
    "\n",
    "A practical way is to make Weather Overview a composite score (0–100) from the latest sensor values plus short-term stability.\n",
    "\n",
    "Suggested model (rule-based, not ML)\n",
    "\n",
    "Comfort Score (55%)\n",
    "Based on temperature + humidity together (use apparent comfort logic).\n",
    "Best zone gets high score, too hot/cold or too humid/dry lowers it.\n",
    "Wind Score (25%)\n",
    "Gentle wind = higher score.\n",
    "Very low or very high wind lowers score (high wind penalized more).\n",
    "Stability Score (20%)\n",
    "Use last 1–3 hours.\n",
    "If temp/humidity/wind are changing smoothly, higher score.\n",
    "Sudden swings reduce score.\n",
    "Then:\n",
    "\n",
    "Overview = 0.55*Comfort + 0.25*Wind + 0.20*Stability\n",
    "Clamp to 0–100.\n",
    "Status label mapping\n",
    "\n",
    "80–100: Optimal\n",
    "60–79: Good\n",
    "40–59: Watch\n",
    "<40: Alert\n",
    "Why this is best for your project\n",
    "\n",
    "Deterministic and explainable (easy for report/demo).\n",
    "No retraining needed.\n",
    "Stable UI behavior if you smooth with a rolling window (for example last 3 points at 5-minute intervals).\n",
    "If you want, next we can agree exact comfort ranges for your climate (tropical vs temperate), then I’ll implement it exactly in the UI/backend.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4d5d4",
   "metadata": {},
   "source": [
    "### DeepLearning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632f3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e1c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class CFG:\n",
    "    # Data\n",
    "    csv_path: str = \"/Users/saikeerthan/Coding/NYP/IOTA/IoT_Weather_project/model-training/datasets/weather_ml_ready.csv\"   # <-- change this to your local file path\n",
    "    datetime_col: str = \"datetime\"           # if your csv uses a different name, change here\n",
    "    lookback_steps: int = 72                 # 72 * 5min = 6 hours\n",
    "    horizon_steps: int = 12                  # 12 * 5min = 60 minutes\n",
    "    # features & targets (edit if your column names differ)\n",
    "    feature_cols: tuple = (\"temp\", \"humi\", \"pres\", \"hour_sin\", \"hour_cos\", \"dayofweek\")\n",
    "    target_cols: tuple = (\"temp_next1h\", \"humi_next1h\", \"pres_next1h\")\n",
    "\n",
    "    # Split fractions (time-based)\n",
    "    train_frac: float = 0.70\n",
    "    val_frac: float = 0.15  # test = remainder\n",
    "\n",
    "    # Training\n",
    "    batch_size: int = 64\n",
    "    num_workers: int = 0\n",
    "    epochs: int = 60\n",
    "    lr: float = 2e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    dropout: float = 0.15\n",
    "    seed: int = 42\n",
    "    patience: int = 10\n",
    "\n",
    "    # Model\n",
    "    tcn_channels: int = 64\n",
    "    tcn_kernel: int = 3\n",
    "    tcn_dilations: tuple = (1, 2, 4, 8)\n",
    "    gru_hidden: int = 64\n",
    "\n",
    "    # Loss weights for multi-task\n",
    "    w_temp: float = 0.4\n",
    "    w_humi: float = 0.3\n",
    "    w_pres: float = 0.3\n",
    "\n",
    "    # Output\n",
    "    out_dir: str = \"runs_weather_dl\"\n",
    "    best_model_name: str = \"best_model.pt\"\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset: sliding windows\n",
    "# -----------------------------\n",
    "class WeatherSeqDataset(Dataset):\n",
    "    def __init__(self, X_seq: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        X_seq: (N, L, F)\n",
    "        y:     (N, 3)\n",
    "        \"\"\"\n",
    "        self.X_seq = torch.from_numpy(X_seq).float()\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_seq.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_seq[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def build_windows(df: pd.DataFrame, feature_cols, target_cols, lookback_steps, horizon_steps):\n",
    "    \"\"\"\n",
    "    Creates samples where:\n",
    "      X = features[t-lookback+1 : t+1]  (length lookback_steps)\n",
    "      y = targets at time t (already aligned as next1h targets)\n",
    "    BUT to avoid leakage, we ensure that the targets correspond to t+1h from the *end* of window.\n",
    "    Since your CSV has *_next1h already, we align y at the window end index.\n",
    "\n",
    "    Returns:\n",
    "      X_seq: (N, lookback_steps, F)\n",
    "      y:     (N, 3)\n",
    "    \"\"\"\n",
    "    feats = df.loc[:, feature_cols].to_numpy()\n",
    "    tars = df.loc[:, target_cols].to_numpy()\n",
    "\n",
    "    L = lookback_steps\n",
    "    # We need the window end index 'end' such that targets are valid there.\n",
    "    # If your *_next1h was computed as shift(-12), then the last 12 rows may be NaN.\n",
    "    # We'll drop NaNs earlier, but still guard.\n",
    "    X_list, y_list = [], []\n",
    "    for end in range(L - 1, len(df)):\n",
    "        start = end - (L - 1)\n",
    "        x = feats[start:end + 1]\n",
    "        y = tars[end]\n",
    "        if np.any(np.isnan(x)) or np.any(np.isnan(y)):\n",
    "            continue\n",
    "        X_list.append(x)\n",
    "        y_list.append(y)\n",
    "\n",
    "    X_seq = np.stack(X_list, axis=0) if len(X_list) else np.empty((0, L, len(feature_cols)))\n",
    "    y = np.stack(y_list, axis=0) if len(y_list) else np.empty((0, len(target_cols)))\n",
    "    return X_seq, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "291d967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Model: TCN residual blocks + GRU + Attention pooling + 3-head outputs\n",
    "# -----------------------------\n",
    "class ResidualTCNBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, dilation, dropout):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation  # for causal conv\n",
    "\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.ln1 = nn.LayerNorm(channels)\n",
    "        self.act1 = nn.GELU()\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.ln2 = nn.LayerNorm(channels)\n",
    "        self.act2 = nn.GELU()\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, C, L)\n",
    "        Causal trimming after conv because of padding.\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = out[:, :, :x.size(2)]  # trim to keep causality\n",
    "        # LayerNorm expects (B, L, C), so transpose\n",
    "        out = out.transpose(1, 2)\n",
    "        out = self.ln1(out)\n",
    "        out = out.transpose(1, 2)\n",
    "\n",
    "        out = self.act1(out)\n",
    "        out = self.drop1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = out[:, :, :x.size(2)]\n",
    "        out = out.transpose(1, 2)\n",
    "        out = self.ln2(out)\n",
    "        out = out.transpose(1, 2)\n",
    "\n",
    "        out = self.act2(out)\n",
    "        out = self.drop2(out)\n",
    "\n",
    "        return out + residual\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.score = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, h):\n",
    "        \"\"\"\n",
    "        h: (B, L, H)\n",
    "        returns: context (B, H)\n",
    "        \"\"\"\n",
    "        # scores: (B, L, 1)\n",
    "        scores = self.score(h)\n",
    "        weights = torch.softmax(scores, dim=1)  # over L\n",
    "        context = torch.sum(weights * h, dim=1)  # (B, H)\n",
    "        return context\n",
    "\n",
    "\n",
    "class WeatherForecastModel(nn.Module):\n",
    "    def __init__(self, num_features, cfg: CFG):\n",
    "        super().__init__()\n",
    "        C = cfg.tcn_channels\n",
    "\n",
    "        self.in_proj = nn.Linear(num_features, C)\n",
    "\n",
    "        self.tcn_blocks = nn.ModuleList([\n",
    "            ResidualTCNBlock(C, cfg.tcn_kernel, d, cfg.dropout) for d in cfg.tcn_dilations\n",
    "        ])\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=C,\n",
    "            hidden_size=cfg.gru_hidden,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "        self.gru_drop = nn.Dropout(cfg.dropout)\n",
    "\n",
    "        self.attn = AttentionPooling(cfg.gru_hidden)\n",
    "\n",
    "        # Shared MLP trunk\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(cfg.gru_hidden, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "        )\n",
    "\n",
    "        # Three heads\n",
    "        self.temp_head = nn.Sequential(nn.Linear(64, 32), nn.GELU(), nn.Linear(32, 1))\n",
    "        self.humi_head = nn.Sequential(nn.Linear(64, 32), nn.GELU(), nn.Linear(32, 1))\n",
    "        self.pres_head = nn.Sequential(nn.Linear(64, 32), nn.GELU(), nn.Linear(32, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, L, F)\n",
    "        \"\"\"\n",
    "        x = self.in_proj(x)  # (B, L, C)\n",
    "\n",
    "        # TCN wants (B, C, L)\n",
    "        x = x.transpose(1, 2)\n",
    "        for block in self.tcn_blocks:\n",
    "            x = block(x)\n",
    "        x = x.transpose(1, 2)  # back to (B, L, C)\n",
    "\n",
    "        h, _ = self.gru(x)  # (B, L, H)\n",
    "        h = self.gru_drop(h)\n",
    "\n",
    "        context = self.attn(h)  # (B, H)\n",
    "        z = self.shared(context)  # (B, 64)\n",
    "\n",
    "        temp = self.temp_head(z)\n",
    "        humi = self.humi_head(z)\n",
    "        pres = self.pres_head(z)\n",
    "\n",
    "        yhat = torch.cat([temp, humi, pres], dim=1)  # (B, 3)\n",
    "        return yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e687792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Metrics\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true/y_pred: torch tensors (N,3)\n",
    "    returns dict of MAE/RMSE per target + mean\n",
    "    \"\"\"\n",
    "    err = y_pred - y_true\n",
    "    mae = torch.mean(torch.abs(err), dim=0)  # (3,)\n",
    "    rmse = torch.sqrt(torch.mean(err**2, dim=0) + 1e-12)\n",
    "\n",
    "    out = {\n",
    "        \"mae_temp\": mae[0].item(), \"mae_humi\": mae[1].item(), \"mae_pres\": mae[2].item(),\n",
    "        \"rmse_temp\": rmse[0].item(), \"rmse_humi\": rmse[1].item(), \"rmse_pres\": rmse[2].item(),\n",
    "        \"mae_mean\": torch.mean(mae).item(),\n",
    "        \"rmse_mean\": torch.mean(rmse).item(),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    ys, preds = [], []\n",
    "    for X, y in loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        yhat = model(X)\n",
    "        ys.append(y)\n",
    "        preds.append(yhat)\n",
    "    y_true = torch.cat(ys, dim=0)\n",
    "    y_pred = torch.cat(preds, dim=0)\n",
    "    return compute_metrics(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a03ad92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Warning: datetime_col='datetime' not found. Assuming rows are time-ordered.\n",
      "Rows: total=2182, train=1527, val=327, test=328\n",
      "Windows: train=(1456, 72, 6), val=(256, 72, 6), test=(257, 72, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/50s4djvj3g5_yz8zn0m59nbm0000gn/T/ipykernel_33922/2711983676.py:100: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.68305752  1.68305752  1.68305752 ... -0.45684992 -0.3595814\n",
      " -0.3595814 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  d.loc[:, cfg.feature_cols] = scaler.transform(arr)\n",
      "/var/folders/_r/50s4djvj3g5_yz8zn0m59nbm0000gn/T/ipykernel_33922/2711983676.py:100: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.99117366 0.99117366 0.99117366 ... 0.99117366 0.99117366 0.99117366]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  d.loc[:, cfg.feature_cols] = scaler.transform(arr)\n",
      "/var/folders/_r/50s4djvj3g5_yz8zn0m59nbm0000gn/T/ipykernel_33922/2711983676.py:100: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.45684992 -0.45684992 -0.45684992 -0.45684992 -0.3595814  -0.3595814\n",
      " -0.45684992 -0.3595814  -0.3595814  -0.3595814  -0.45684992 -0.3595814\n",
      " -0.45684992 -0.45684992 -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.45684992 -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.45684992 -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.45684992 -0.45684992 -0.45684992 -0.45684992 -0.45684992\n",
      " -0.45684992 -0.45684992 -0.45684992 -0.45684992 -0.45684992 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.65138696 -0.65138696 -0.65138696\n",
      " -0.65138696 -0.65138696 -0.65138696 -0.65138696 -0.74865548 -0.74865548\n",
      " -0.74865548 -0.74865548 -0.65138696 -0.74865548 -0.74865548 -0.74865548\n",
      " -0.74865548 -0.845924   -0.845924   -0.845924   -0.845924   -0.845924\n",
      " -0.845924   -0.845924   -0.845924   -0.845924   -0.845924   -0.845924\n",
      " -0.845924   -0.845924   -0.845924   -0.845924   -0.845924   -0.845924\n",
      " -0.845924   -0.94319252 -0.845924   -0.845924   -0.94319252 -0.94319252\n",
      " -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.94319252\n",
      " -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104\n",
      " -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104\n",
      " -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104\n",
      " -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104\n",
      " -1.04046104 -1.13772956 -1.04046104 -1.04046104 -1.04046104 -1.04046104\n",
      " -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104\n",
      " -1.04046104 -0.94319252 -1.04046104 -0.94319252 -1.04046104 -0.94319252\n",
      " -0.94319252 -0.845924   -0.845924   -0.845924   -0.845924   -0.845924\n",
      " -0.845924   -0.845924   -0.845924   -0.845924   -0.845924   -0.845924\n",
      " -0.74865548 -0.845924   -0.94319252 -0.94319252 -0.94319252 -0.94319252\n",
      " -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.845924   -0.845924\n",
      " -0.845924   -0.845924   -0.845924   -0.845924   -0.845924   -0.845924\n",
      " -0.845924   -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548\n",
      " -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548\n",
      " -0.74865548 -0.74865548 -0.65138696 -0.65138696 -0.65138696 -0.65138696\n",
      " -0.65138696 -0.65138696 -0.65138696 -0.65138696 -0.65138696 -0.65138696\n",
      " -0.65138696 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.45684992 -0.55411844\n",
      " -0.45684992 -0.45684992 -0.45684992 -0.3595814  -0.3595814  -0.26231288\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  d.loc[:, cfg.feature_cols] = scaler.transform(arr)\n",
      "/var/folders/_r/50s4djvj3g5_yz8zn0m59nbm0000gn/T/ipykernel_33922/2711983676.py:100: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366 0.99117366\n",
      " 0.99117366 0.99117366 0.99117366 0.99117366 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167 1.50009167\n",
      " 1.50009167 1.50009167 1.50009167]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  d.loc[:, cfg.feature_cols] = scaler.transform(arr)\n",
      "/var/folders/_r/50s4djvj3g5_yz8zn0m59nbm0000gn/T/ipykernel_33922/2711983676.py:100: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.26231288\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.3595814  -0.45684992 -0.45684992\n",
      " -0.45684992 -0.45684992 -0.3595814  -0.3595814  -0.45684992 -0.3595814\n",
      " -0.3595814  -0.3595814  -0.3595814  -0.45684992 -0.45684992 -0.45684992\n",
      " -0.45684992 -0.45684992 -0.45684992 -0.45684992 -0.45684992 -0.45684992\n",
      " -0.45684992 -0.45684992 -0.45684992 -0.45684992 -0.45684992 -0.45684992\n",
      " -0.45684992 -0.45684992 -0.45684992 -0.45684992 -0.45684992 -0.45684992\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.65138696 -0.65138696 -0.65138696\n",
      " -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548\n",
      " -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.845924   -0.845924\n",
      " -0.845924   -0.845924   -0.74865548 -0.845924   -0.74865548 -0.74865548\n",
      " -0.845924   -0.845924   -0.845924   -0.845924   -0.94319252 -0.845924\n",
      " -0.845924   -0.845924   -0.845924   -0.845924   -0.845924   -0.94319252\n",
      " -0.845924   -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.845924\n",
      " -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.94319252\n",
      " -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.94319252 -1.04046104\n",
      " -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.94319252\n",
      " -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.94319252 -1.04046104\n",
      " -1.04046104 -0.94319252 -1.04046104 -1.04046104 -1.04046104 -0.94319252\n",
      " -1.04046104 -0.94319252 -1.04046104 -1.04046104 -1.04046104 -0.94319252\n",
      " -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104 -1.04046104\n",
      " -1.04046104 -0.94319252 -1.04046104 -1.04046104 -1.04046104 -0.94319252\n",
      " -0.94319252 -1.04046104 -0.94319252 -1.04046104 -0.94319252 -1.04046104\n",
      " -1.04046104 -0.94319252 -0.94319252 -0.94319252 -1.04046104 -0.94319252\n",
      " -0.94319252 -1.04046104 -1.04046104 -1.04046104 -1.04046104 -0.94319252\n",
      " -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.94319252 -0.94319252\n",
      " -0.94319252 -0.94319252 -0.94319252 -0.845924   -0.845924   -0.845924\n",
      " -0.845924   -0.845924   -0.845924   -0.845924   -0.845924   -0.845924\n",
      " -0.845924   -0.845924   -0.845924   -0.845924   -0.845924   -0.845924\n",
      " -0.845924   -0.845924   -0.845924   -0.845924   -0.845924   -0.845924\n",
      " -0.845924   -0.74865548 -0.74865548 -0.74865548 -0.845924   -0.845924\n",
      " -0.845924   -0.845924   -0.845924   -0.845924   -0.74865548 -0.845924\n",
      " -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548\n",
      " -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548\n",
      " -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548\n",
      " -0.74865548 -0.65138696 -0.65138696 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.65138696 -0.65138696 -0.65138696 -0.65138696\n",
      " -0.65138696 -0.65138696 -0.65138696 -0.65138696 -0.55411844 -0.55411844\n",
      " -0.65138696 -0.55411844 -0.65138696 -0.55411844 -0.55411844 -0.65138696\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.65138696 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.65138696 -0.55411844 -0.65138696 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.65138696 -0.65138696 -0.55411844\n",
      " -0.55411844 -0.65138696 -0.65138696 -0.65138696 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.65138696 -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.55411844\n",
      " -0.55411844 -0.55411844 -0.55411844 -0.55411844 -0.65138696 -0.65138696\n",
      " -0.65138696 -0.65138696 -0.74865548 -0.74865548 -0.74865548 -0.74865548\n",
      " -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548\n",
      " -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.74865548 -0.845924\n",
      " -0.845924   -0.845924   -0.845924   -0.845924  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  d.loc[:, cfg.feature_cols] = scaler.transform(arr)\n",
      "/var/folders/_r/50s4djvj3g5_yz8zn0m59nbm0000gn/T/ipykernel_33922/2711983676.py:100: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      "  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167  1.50009167\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641 -1.55341641\n",
      " -1.55341641 -1.55341641 -1.55341641 -1.55341641]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  d.loc[:, cfg.feature_cols] = scaler.transform(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 001 | train_loss=332.7471 | val_mae_mean=359.0544 | val_rmse_mean=359.0852 | dt=3.4s\n",
      "  Val MAE: temp=30.4184, humi=40.2524, pres=1006.4922 | RMSE: temp=30.4269, humi=40.3354, pres=1006.4932\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 002 | train_loss=312.1450 | val_mae_mean=322.9300 | val_rmse_mean=323.1014 | dt=3.2s\n",
      "  Val MAE: temp=0.6081, humi=2.3809, pres=965.8009 | RMSE: temp=0.7388, humi=2.7636, pres=965.8018\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 003 | train_loss=284.8090 | val_mae_mean=301.6325 | val_rmse_mean=301.7746 | dt=3.3s\n",
      "  Val MAE: temp=5.1861, humi=8.7042, pres=891.0072 | RMSE: temp=5.2358, humi=9.0797, pres=891.0082\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 004 | train_loss=251.1168 | val_mae_mean=249.2419 | val_rmse_mean=249.4491 | dt=3.3s\n",
      "  Val MAE: temp=3.0703, humi=2.6897, pres=741.9658 | RMSE: temp=3.1534, humi=3.2269, pres=741.9670\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 005 | train_loss=190.9351 | val_mae_mean=167.6232 | val_rmse_mean=167.7682 | dt=3.3s\n",
      "  Val MAE: temp=3.5855, humi=2.3671, pres=496.9169 | RMSE: temp=3.6569, humi=2.7291, pres=496.9186\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 006 | train_loss=98.7641 | val_mae_mean=52.2149 | val_rmse_mean=52.3301 | dt=3.5s\n",
      "  Val MAE: temp=4.1131, humi=2.3129, pres=150.2188 | RMSE: temp=4.1754, humi=2.5904, pres=150.2246\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 007 | train_loss=25.6822 | val_mae_mean=25.6075 | val_rmse_mean=25.7442 | dt=3.3s\n",
      "  Val MAE: temp=3.5997, humi=2.3301, pres=70.8927 | RMSE: temp=3.6709, humi=2.6568, pres=70.9050\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 008 | train_loss=22.3841 | val_mae_mean=22.1601 | val_rmse_mean=22.2836 | dt=3.3s\n",
      "  Val MAE: temp=5.6258, humi=2.3263, pres=58.5281 | RMSE: temp=5.6716, humi=2.6361, pres=58.5430\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 009 | train_loss=21.8910 | val_mae_mean=20.0517 | val_rmse_mean=20.1938 | dt=3.4s\n",
      "  Val MAE: temp=2.2406, humi=2.3079, pres=55.6065 | RMSE: temp=2.3532, humi=2.6061, pres=55.6221\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 010 | train_loss=21.5970 | val_mae_mean=16.4748 | val_rmse_mean=16.6339 | dt=3.4s\n",
      "  Val MAE: temp=3.4052, humi=2.3768, pres=43.6424 | RMSE: temp=3.4803, humi=2.7590, pres=43.6623\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 011 | train_loss=21.7297 | val_mae_mean=17.5804 | val_rmse_mean=17.7143 | dt=3.3s\n",
      "  Val MAE: temp=4.0495, humi=2.3396, pres=46.3521 | RMSE: temp=4.1129, humi=2.6591, pres=46.3708\n",
      "Epoch 012 | train_loss=22.1512 | val_mae_mean=14.2686 | val_rmse_mean=14.5407 | dt=3.3s\n",
      "  Val MAE: temp=3.9131, humi=3.0243, pres=35.8683 | RMSE: temp=3.9786, humi=3.7510, pres=35.8925\n",
      "  ✅ Saved best model to: runs_weather_dl/best_model.pt\n",
      "Epoch 013 | train_loss=22.2171 | val_mae_mean=17.2062 | val_rmse_mean=17.3673 | dt=3.3s\n",
      "  Val MAE: temp=3.5553, humi=2.3941, pres=45.6691 | RMSE: temp=3.6273, humi=2.7865, pres=45.6881\n",
      "Epoch 014 | train_loss=21.4444 | val_mae_mean=15.4064 | val_rmse_mean=15.5429 | dt=3.3s\n",
      "  Val MAE: temp=2.5682, humi=2.3202, pres=41.3307 | RMSE: temp=2.6670, humi=2.6100, pres=41.3518\n",
      "Epoch 015 | train_loss=21.2454 | val_mae_mean=20.6111 | val_rmse_mean=20.8413 | dt=3.3s\n",
      "  Val MAE: temp=3.7766, humi=2.8188, pres=55.2379 | RMSE: temp=3.8445, humi=3.4259, pres=55.2537\n",
      "Epoch 016 | train_loss=22.4637 | val_mae_mean=22.4996 | val_rmse_mean=22.6188 | dt=3.3s\n",
      "  Val MAE: temp=4.0578, humi=2.3152, pres=61.1260 | RMSE: temp=4.1210, humi=2.5953, pres=61.1402\n",
      "Epoch 017 | train_loss=21.9142 | val_mae_mean=16.4189 | val_rmse_mean=16.5362 | dt=3.2s\n",
      "  Val MAE: temp=4.7540, humi=2.3074, pres=42.1953 | RMSE: temp=4.8081, humi=2.5846, pres=42.2158\n",
      "Epoch 018 | train_loss=21.7301 | val_mae_mean=19.9710 | val_rmse_mean=20.0958 | dt=3.3s\n",
      "  Val MAE: temp=4.7882, humi=2.3221, pres=52.8028 | RMSE: temp=4.8419, humi=2.6263, pres=52.8191\n",
      "Epoch 019 | train_loss=22.1627 | val_mae_mean=15.8707 | val_rmse_mean=16.0911 | dt=3.3s\n",
      "  Val MAE: temp=3.8699, humi=2.5411, pres=41.2011 | RMSE: temp=3.9361, humi=3.1149, pres=41.2222\n",
      "Epoch 020 | train_loss=21.8010 | val_mae_mean=21.5982 | val_rmse_mean=21.7398 | dt=3.3s\n",
      "  Val MAE: temp=2.8109, humi=2.3398, pres=59.6438 | RMSE: temp=2.9014, humi=2.6595, pres=59.6583\n",
      "Epoch 021 | train_loss=21.9936 | val_mae_mean=21.8711 | val_rmse_mean=21.9859 | dt=3.3s\n",
      "  Val MAE: temp=5.1963, humi=2.3150, pres=58.1022 | RMSE: temp=5.2458, humi=2.5947, pres=58.1171\n",
      "Epoch 022 | train_loss=21.3171 | val_mae_mean=15.0942 | val_rmse_mean=15.2532 | dt=3.3s\n",
      "  Val MAE: temp=2.8727, humi=2.3694, pres=40.0405 | RMSE: temp=2.9613, humi=2.7361, pres=40.0622\n",
      "\n",
      "Early stopping triggered. Best epoch = 12 (val_mae_mean=14.2686)\n",
      "\n",
      "===== TEST RESULTS =====\n",
      "MAE:  temp=3.8227, humi=3.8345, pres=35.5855 | mean=14.4143\n",
      "RMSE: temp=3.9188, humi=4.2184, pres=35.6065 | mean=14.5812\n",
      "\n",
      "Done ✅\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Train\n",
    "# -----------------------------\n",
    "def train_one_epoch(model, loader, optimizer, loss_fn, device, cfg: CFG):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    n = 0\n",
    "    for X, y in loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        yhat = model(X)\n",
    "\n",
    "        # Huber per target, weighted\n",
    "        loss_temp = loss_fn(yhat[:, 0], y[:, 0])\n",
    "        loss_humi = loss_fn(yhat[:, 1], y[:, 1])\n",
    "        loss_pres = loss_fn(yhat[:, 2], y[:, 2])\n",
    "        loss = cfg.w_temp * loss_temp + cfg.w_humi * loss_humi + cfg.w_pres * loss_pres\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running += loss.item() * X.size(0)\n",
    "        n += X.size(0)\n",
    "\n",
    "    return running / max(n, 1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--csv\", type=str, default=None, help=\"Path to weather_ml_ready.csv\")\n",
    "    parser.add_argument(\"--datetime_col\", type=str, default=None, help=\"Datetime column name\")\n",
    "    parser.add_argument(\"--lookback\", type=int, default=None, help=\"Lookback steps (default 72)\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=None, help=\"Epochs (default 60)\")\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    cfg = CFG()\n",
    "    if args.csv: cfg.csv_path = args.csv\n",
    "    if args.datetime_col: cfg.datetime_col = args.datetime_col\n",
    "    if args.lookback: cfg.lookback_steps = args.lookback\n",
    "    if args.epochs: cfg.epochs = args.epochs\n",
    "\n",
    "    set_seed(cfg.seed)\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Load + clean\n",
    "    # -----------------------------\n",
    "    df = pd.read_csv(cfg.csv_path)\n",
    "\n",
    "    # Parse datetime if present\n",
    "    if cfg.datetime_col in df.columns:\n",
    "        df[cfg.datetime_col] = pd.to_datetime(df[cfg.datetime_col], errors=\"coerce\")\n",
    "        df = df.sort_values(cfg.datetime_col).reset_index(drop=True)\n",
    "    else:\n",
    "        # If no datetime column, assume already ordered\n",
    "        print(f\"Warning: datetime_col='{cfg.datetime_col}' not found. Assuming rows are time-ordered.\")\n",
    "\n",
    "    # Keep required columns only\n",
    "    needed = list(cfg.feature_cols) + list(cfg.target_cols)\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"Missing columns in CSV: {missing}\\n\"\n",
    "            f\"Available columns: {list(df.columns)}\\n\"\n",
    "            f\"Edit CFG.feature_cols / CFG.target_cols / CFG.datetime_col to match your CSV.\"\n",
    "        )\n",
    "\n",
    "    # Drop NaNs in required columns\n",
    "    df = df.dropna(subset=needed).reset_index(drop=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Time-based split indices (on rows)\n",
    "    # We'll build windows after split to avoid mixing times.\n",
    "    # -----------------------------\n",
    "    n_total = len(df)\n",
    "    n_train = int(cfg.train_frac * n_total)\n",
    "    n_val = int(cfg.val_frac * n_total)\n",
    "    n_test = n_total - n_train - n_val\n",
    "\n",
    "    df_train = df.iloc[:n_train].copy()\n",
    "    df_val = df.iloc[n_train:n_train + n_val].copy()\n",
    "    df_test = df.iloc[n_train + n_val:].copy()\n",
    "\n",
    "    print(f\"Rows: total={n_total}, train={len(df_train)}, val={len(df_val)}, test={len(df_test)}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Standardize features using TRAIN only\n",
    "    # -----------------------------\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_train.loc[:, cfg.feature_cols].to_numpy())\n",
    "\n",
    "    def apply_scaler(d):\n",
    "        arr = d.loc[:, cfg.feature_cols].to_numpy()\n",
    "        d.loc[:, cfg.feature_cols] = scaler.transform(arr)\n",
    "        return d\n",
    "\n",
    "    df_train = apply_scaler(df_train)\n",
    "    df_val = apply_scaler(df_val)\n",
    "    df_test = apply_scaler(df_test)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Build windows within each split\n",
    "    # Important: windows do not cross split boundaries\n",
    "    # -----------------------------\n",
    "    X_train, y_train = build_windows(df_train, cfg.feature_cols, cfg.target_cols, cfg.lookback_steps, cfg.horizon_steps)\n",
    "    X_val, y_val = build_windows(df_val, cfg.feature_cols, cfg.target_cols, cfg.lookback_steps, cfg.horizon_steps)\n",
    "    X_test, y_test = build_windows(df_test, cfg.feature_cols, cfg.target_cols, cfg.lookback_steps, cfg.horizon_steps)\n",
    "\n",
    "    if X_train.shape[0] == 0 or X_val.shape[0] == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No windows were created. This usually means your splits are too small for the lookback length.\\n\"\n",
    "            \"Try reducing lookback_steps (e.g., 48) or increasing dataset length.\"\n",
    "        )\n",
    "\n",
    "    print(f\"Windows: train={X_train.shape}, val={X_val.shape}, test={X_test.shape}\")\n",
    "\n",
    "    train_ds = WeatherSeqDataset(X_train, y_train)\n",
    "    val_ds = WeatherSeqDataset(X_val, y_val)\n",
    "    test_ds = WeatherSeqDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, drop_last=False)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "    test_loader = DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Model\n",
    "    # -----------------------------\n",
    "    model = WeatherForecastModel(num_features=len(cfg.feature_cols), cfg=cfg).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    loss_fn = nn.HuberLoss(delta=1.0)\n",
    "\n",
    "    best = {\n",
    "        \"epoch\": -1,\n",
    "        \"val_mae_mean\": float(\"inf\"),\n",
    "        \"state\": None,\n",
    "    }\n",
    "    patience_counter = 0\n",
    "\n",
    "    print(\"\\nStarting training...\\n\")\n",
    "\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        t0 = time.time()\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, device, cfg)\n",
    "        val_metrics = evaluate(model, val_loader, device)\n",
    "\n",
    "        dt = time.time() - t0\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d} | \"\n",
    "            f\"train_loss={train_loss:.4f} | \"\n",
    "            f\"val_mae_mean={val_metrics['mae_mean']:.4f} | \"\n",
    "            f\"val_rmse_mean={val_metrics['rmse_mean']:.4f} | \"\n",
    "            f\"dt={dt:.1f}s\"\n",
    "        )\n",
    "        print(\n",
    "            f\"  Val MAE: temp={val_metrics['mae_temp']:.4f}, humi={val_metrics['mae_humi']:.4f}, pres={val_metrics['mae_pres']:.4f} | \"\n",
    "            f\"RMSE: temp={val_metrics['rmse_temp']:.4f}, humi={val_metrics['rmse_humi']:.4f}, pres={val_metrics['rmse_pres']:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Early stopping on mean MAE\n",
    "        if val_metrics[\"mae_mean\"] < best[\"val_mae_mean\"] - 1e-5:\n",
    "            best[\"epoch\"] = epoch\n",
    "            best[\"val_mae_mean\"] = val_metrics[\"mae_mean\"]\n",
    "            best[\"state\"] = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "\n",
    "            save_path = os.path.join(cfg.out_dir, cfg.best_model_name)\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": best[\"state\"],\n",
    "                    \"scaler_mean\": scaler.mean_,\n",
    "                    \"scaler_scale\": scaler.scale_,\n",
    "                    \"feature_cols\": cfg.feature_cols,\n",
    "                    \"target_cols\": cfg.target_cols,\n",
    "                    \"cfg\": cfg.__dict__,\n",
    "                },\n",
    "                save_path,\n",
    "            )\n",
    "            print(f\"  ✅ Saved best model to: {save_path}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= cfg.patience:\n",
    "                print(f\"\\nEarly stopping triggered. Best epoch = {best['epoch']} (val_mae_mean={best['val_mae_mean']:.4f})\")\n",
    "                break\n",
    "\n",
    "    # Load best and test\n",
    "    if best[\"state\"] is not None:\n",
    "        model.load_state_dict(best[\"state\"])\n",
    "\n",
    "    test_metrics = evaluate(model, test_loader, device)\n",
    "    print(\"\\n===== TEST RESULTS =====\")\n",
    "    print(\n",
    "        f\"MAE:  temp={test_metrics['mae_temp']:.4f}, humi={test_metrics['mae_humi']:.4f}, pres={test_metrics['mae_pres']:.4f} | mean={test_metrics['mae_mean']:.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"RMSE: temp={test_metrics['rmse_temp']:.4f}, humi={test_metrics['rmse_humi']:.4f}, pres={test_metrics['rmse_pres']:.4f} | mean={test_metrics['rmse_mean']:.4f}\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nDone ✅\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e343f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temp</th>\n",
       "      <th>humi</th>\n",
       "      <th>pres</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>temp_lag1</th>\n",
       "      <th>temp_lag2</th>\n",
       "      <th>temp_lag3</th>\n",
       "      <th>humi_lag1</th>\n",
       "      <th>humi_lag2</th>\n",
       "      <th>humi_lag3</th>\n",
       "      <th>pres_lag1</th>\n",
       "      <th>pres_lag2</th>\n",
       "      <th>pres_lag3</th>\n",
       "      <th>temp_next1h</th>\n",
       "      <th>humi_next1h</th>\n",
       "      <th>pres_next1h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-24 20:38:02</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1016.859131</td>\n",
       "      <td>1016.802490</td>\n",
       "      <td>1016.746582</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1017.522461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-24 20:43:02</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>1016.859131</td>\n",
       "      <td>1016.802490</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1017.663086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-24 20:48:02</td>\n",
       "      <td>28.9</td>\n",
       "      <td>74</td>\n",
       "      <td>1017.078125</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>1016.859131</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1017.696777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-24 20:53:02</td>\n",
       "      <td>28.7</td>\n",
       "      <td>74</td>\n",
       "      <td>1017.150879</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1017.078125</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>1016.934326</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1017.770752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-24 20:58:02</td>\n",
       "      <td>28.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1017.206299</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.7</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1017.150879</td>\n",
       "      <td>1017.078125</td>\n",
       "      <td>1016.971436</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1017.850830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>2026-02-02 09:26:15</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48</td>\n",
       "      <td>1017.980957</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.2</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1018.028076</td>\n",
       "      <td>1017.984131</td>\n",
       "      <td>1017.997070</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.157959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>2026-02-02 09:31:15</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48</td>\n",
       "      <td>1018.037842</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1017.980957</td>\n",
       "      <td>1018.028076</td>\n",
       "      <td>1017.984131</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.206055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>2026-02-02 09:36:15</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48</td>\n",
       "      <td>1018.024414</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1018.037842</td>\n",
       "      <td>1017.980957</td>\n",
       "      <td>1018.028076</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.149414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>2026-02-02 09:41:15</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48</td>\n",
       "      <td>1018.083984</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1018.024414</td>\n",
       "      <td>1018.037842</td>\n",
       "      <td>1017.980957</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.127930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>2026-02-02 09:46:15</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48</td>\n",
       "      <td>1018.033691</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1018.083984</td>\n",
       "      <td>1018.024414</td>\n",
       "      <td>1018.037842</td>\n",
       "      <td>38.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.202881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  temp  humi         pres  hour  dayofweek  hour_sin  \\\n",
       "0     2026-01-24 20:38:02  28.5    74  1016.934326    20          5 -0.866025   \n",
       "1     2026-01-24 20:43:02  28.6    74  1016.971436    20          5 -0.866025   \n",
       "2     2026-01-24 20:48:02  28.9    74  1017.078125    20          5 -0.866025   \n",
       "3     2026-01-24 20:53:02  28.7    74  1017.150879    20          5 -0.866025   \n",
       "4     2026-01-24 20:58:02  28.5    74  1017.206299    20          5 -0.866025   \n",
       "...                   ...   ...   ...          ...   ...        ...       ...   \n",
       "2177  2026-02-02 09:26:15  38.3    48  1017.980957     9          0  0.707107   \n",
       "2178  2026-02-02 09:31:15  38.3    48  1018.037842     9          0  0.707107   \n",
       "2179  2026-02-02 09:36:15  38.3    48  1018.024414     9          0  0.707107   \n",
       "2180  2026-02-02 09:41:15  38.3    48  1018.083984     9          0  0.707107   \n",
       "2181  2026-02-02 09:46:15  38.3    48  1018.033691     9          0  0.707107   \n",
       "\n",
       "      hour_cos  temp_lag1  temp_lag2  temp_lag3  humi_lag1  humi_lag2  \\\n",
       "0     0.500000       28.6       28.5       28.6       74.0       74.0   \n",
       "1     0.500000       28.5       28.6       28.5       74.0       74.0   \n",
       "2     0.500000       28.6       28.5       28.6       74.0       74.0   \n",
       "3     0.500000       28.9       28.6       28.5       74.0       74.0   \n",
       "4     0.500000       28.7       28.9       28.6       74.0       74.0   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "2177 -0.707107       38.1       38.3       38.2       49.0       49.0   \n",
       "2178 -0.707107       38.3       38.1       38.3       48.0       49.0   \n",
       "2179 -0.707107       38.3       38.3       38.1       48.0       48.0   \n",
       "2180 -0.707107       38.3       38.3       38.3       48.0       48.0   \n",
       "2181 -0.707107       38.3       38.3       38.3       48.0       48.0   \n",
       "\n",
       "      humi_lag3    pres_lag1    pres_lag2    pres_lag3  temp_next1h  \\\n",
       "0          74.0  1016.859131  1016.802490  1016.746582         28.5   \n",
       "1          74.0  1016.934326  1016.859131  1016.802490         28.5   \n",
       "2          74.0  1016.971436  1016.934326  1016.859131         28.5   \n",
       "3          74.0  1017.078125  1016.971436  1016.934326         28.5   \n",
       "4          74.0  1017.150879  1017.078125  1016.971436         28.5   \n",
       "...         ...          ...          ...          ...          ...   \n",
       "2177       49.0  1018.028076  1017.984131  1017.997070         38.5   \n",
       "2178       49.0  1017.980957  1018.028076  1017.984131         38.5   \n",
       "2179       49.0  1018.037842  1017.980957  1018.028076         38.5   \n",
       "2180       48.0  1018.024414  1018.037842  1017.980957         38.5   \n",
       "2181       48.0  1018.083984  1018.024414  1018.037842         38.5   \n",
       "\n",
       "      humi_next1h  pres_next1h  \n",
       "0            75.0  1017.522461  \n",
       "1            75.0  1017.663086  \n",
       "2            75.0  1017.696777  \n",
       "3            75.0  1017.770752  \n",
       "4            75.0  1017.850830  \n",
       "...           ...          ...  \n",
       "2177         47.0  1018.157959  \n",
       "2178         47.0  1018.206055  \n",
       "2179         47.0  1018.149414  \n",
       "2180         47.0  1018.127930  \n",
       "2181         47.0  1018.202881  \n",
       "\n",
       "[2182 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "CSV_ROOT = Path(\"/Users/saikeerthan/Coding/NYP/IOTA/IoT_Weather_project/model-training/datasets/weather_ml_ready.csv\")\n",
    "\n",
    "df = pd.read_csv(CSV_ROOT)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5680d1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pres</th>\n",
       "      <th>pres_next1h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2182.000000</td>\n",
       "      <td>2182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1016.879020</td>\n",
       "      <td>1016.883789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.145357</td>\n",
       "      <td>1.148706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1014.175293</td>\n",
       "      <td>1014.175293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1016.000732</td>\n",
       "      <td>1016.000732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1016.865722</td>\n",
       "      <td>1016.865722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1017.856445</td>\n",
       "      <td>1017.871521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1019.418457</td>\n",
       "      <td>1019.418457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pres  pres_next1h\n",
       "count  2182.000000  2182.000000\n",
       "mean   1016.879020  1016.883789\n",
       "std       1.145357     1.148706\n",
       "min    1014.175293  1014.175293\n",
       "25%    1016.000732  1016.000732\n",
       "50%    1016.865722  1016.865722\n",
       "75%    1017.856445  1017.871521\n",
       "max    1019.418457  1019.418457"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"pres\",\"pres_next1h\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0e0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
